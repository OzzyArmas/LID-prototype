#!/usr/bin/env python

from models import gmm
import pandas as pd
import numpy as np
import os
import traceback
import sys
import pickle
import json
import time
import ast
import logging

prefix = '/opt/ml/'
input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

channel = 'training'
training_path = os.path.join(input_path, channel)
train_data = os.path.join(training_path, 'train')
test_data = os.path.join(training_path, 'test')

logger = logging.getLogger('instance')
lvl = logging.WARNING
debug = False
#load params

def eval(model):
    data_y = {}
    data_x = []
    global debug

    for idx, language in enumerate(os.listdir(test_data)):
        data_y[language[:-4]] = idx
        if debug:
            data_x.append(pd.read_csv(os.path.join(test_data, language)).as_matrix()[:750])
        else:
            data_x.append(pd.read_csv(os.path.join(test_data, language)).as_matrix())

    if len(data_x) == 0:
        raise Exception('no data was loaded')
    
    #accuracy
    acc = {}
    for lang in data_y:
        pred = model.predict_all(data_x[data_y[lang]])
        acc[lang] = np.average(pred == data_y[lang])
    return acc

def train(model, data_x, data_y):
    '''
    train(x,y)
    '''
    #separate data into snippet_length samples
    #features_es.reshape((int(np.shape(features_es)[0] / sample_length), sample_length, -1))
    for lang in data_y:
        x = data_x[data_y[lang]]
        model.train(x,data_y[lang])


    return model

def get_data():
    '''
    '''
    global debug
    logger.log(lvl, f'debug2: {debug}')
    data_y = {}
    data_x = []
    for idx, language in enumerate(os.listdir(train_data)):
        data_y[language[:-4]] = idx
        if debug:
            data_x.append(pd.read_csv(os.path.join(train_data, language)).as_matrix()[:750])
        else:
            data_x.append(pd.read_csv(os.path.join(train_data, language)).as_matrix())

    if len(data_x) == 0:
        raise Exception('no data was loaded')

    return (data_x, data_y)
        
    
def save_model(model, acc):
    '''
    dump model to a pickle
    dump pickle on S3
    '''
    file_name = f'''gmm_clust-{str(model.clusters)}_acc-{int(acc * 100)}.plk'''

    with open(os.path.join(model_path, file_name), 'wb') as out:
        pickle.dump(model, out)
    
def create_model(languages, training_params):
    '''
    read from parampath and figure out how to create model
    hyper parameters for gmm.GMM()
    n_clusters = 30, cov_type='full', iter = 100, snippet_length=75, languages=2
    '''
    global debug
    clusters = ast.literal_eval(training_params.get('n_clusters', 30))
    covar = training_params.get('cov_type', 'full')
    it = training_params.get('iter', 100)
    snip = training_params.get('snippet_length', 75)
    languages = training_params.get('languages', languages)
    debug = training_params.get('debug', False)
    logger.log(lvl, type(clusters))
    return gmm.GMM(clusters, covar, it, snip, languages)

if __name__ == '__main__':
    try:
        with open(param_path, 'r') as hyper:
            training_params = json.load(hyper)
        
        logger.log(lvl, f'debug : {debug}' )

        # Array of data_x, and data_y values
        data_x, data_y = get_data() 
        logger.log(lvl, '[SUCCESS] data parsed')
        #create a model based on hyper_params
        model = create_model(len(data_y), training_params)
        logger.log(lvl, '[SUCCESS] model created')

        #trains model from the parsed s3 data
        model = train(model,data_x, data_y)
        logger.log(lvl, '[SUCCESS] model trained')

        #saves a checkpoint
        save_model(model, 0)
        logger.log(lvl, '[SUCCESS] checkpoint saved')

        #Tries test data to measure accuracy and evaluate model
        acc = eval(model)
        logg.log(lvl, f'[SUCCESS] acc: {acc}')

        #save model as a pickle
        save_model(model, acc)
        logger.log(lvl, '[SUCCESS] model saved')

    except Exception as e:
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as err:
            err.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)