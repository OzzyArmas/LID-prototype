{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models import lstm\n",
    "import importlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 39\n",
    "hidden = 512\n",
    "languages = 2\n",
    "snippet_length = 75\n",
    "batch size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4939049, 39)\n",
      "(1760399, 39)\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/oosv/data/csv'\n",
    "data_en = pd.read_csv(f\"{data_path}/english_data.csv\").values.astype(np.float32)\n",
    "data_es = pd.read_csv(f\"{data_path}/spanish_data.csv\").values.astype(np.float32)\n",
    "print(np.shape(data_en))\n",
    "print(np.shape(data_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape data in 3 dimensions and prepare for training\n",
    "data_en_sampled = np.reshape(data_en[74:], (-1,75,39))\n",
    "data_es_sampled = np.reshape(data_es[74:], (-1,75,39))\n",
    "en_idx = int(len(data_en_sampled)/4)\n",
    "es_idx = int(len(data_es_sampled)/4)\n",
    "\n",
    "# Training models on equal amounts of data\n",
    "train_en = data_en_sampled[es_idx:len(data_es_sampled)]\n",
    "train_es = data_es_sampled[es_idx:]\n",
    "test_en = data_en_sampled[:es_idx]\n",
    "test_es = data_en_sampled[:es_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17604, 75, 39) (17604, 75, 39)\n",
      "(5867, 75, 39) (5867, 75, 39)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_en), np.shape(train_es))\n",
    "print(np.shape(test_en), np.shape(test_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35208, 75, 39)\n",
      "(35208, 75, 1)\n"
     ]
    }
   ],
   "source": [
    "#train_data = np.concatenate((train_en, train_es), axis = 0)\n",
    "shape_es = np.shape(train_en)\n",
    "shape_en = np.shape(train_es)\n",
    "train_labels = np.concatenate((np.zeros((shape_en[0],shape_en[1],1)), np.ones((shape_es[0],shape_es[1],1))), axis = 0)\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.4133883e+00 -1.9497540e+01  3.9959562e+00  5.6146326e+00\n",
      " -6.8843942e+00  1.2543772e+01 -1.0601465e+00 -1.8551652e+00\n",
      "  3.9233890e-01 -8.9237595e+00  1.3722342e+00 -2.4326236e+00\n",
      " -2.9970469e+00 -6.0930759e-02  3.9699584e-02 -2.6023310e-02\n",
      " -3.0821905e-01  9.3048459e-01  1.2305728e+00 -2.7709448e-01\n",
      " -2.6436749e+00 -1.6095033e+00 -3.6033112e-01  5.6367183e-01\n",
      "  3.8722613e-01  6.2193286e-01  9.1716774e-02 -6.6639298e-01\n",
      " -4.6228880e-01  2.3709337e-01 -4.1993576e-01 -3.0728883e-01\n",
      " -2.6667345e-01  9.7258455e-01  1.6678059e-02  1.0791121e+00\n",
      " -1.1346647e+00  5.6959257e-02 -9.5459871e-02]\n",
      "[ 16.331465   -15.14927      2.432831   -10.573003    -1.8485426\n",
      "  14.230032    14.348568    12.307588    -1.3211254   -6.4342237\n",
      "  12.163789    -7.7444263   10.754949     0.5930134   -2.4643674\n",
      "   1.3112882   -4.356198    -3.3050075    5.252328    -0.5415032\n",
      "   0.3599433    0.7070114   -4.9063616    1.5746101   -1.5614756\n",
      "   2.0184734   -0.16678551   0.59325886  -0.509352     1.6668657\n",
      "   1.060825    -1.0839086    0.0386252   -0.12028942   0.30409658\n",
      "   1.2556853   -1.2416795   -0.18222985  -1.8116189 ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][0])\n",
    "shuffle_in_unison(train_data, train_labels)\n",
    "print(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(lstm)\n",
    "_lstm = lstm.LSTM()\n",
    "# _train_data = torch.tensor(train_data)\n",
    "# _train_labels = torch.tensor(train_labels)\n",
    "# print(_train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.0377087593078613, epoch: 0 iter: 1\n",
      "loss: 2.0557773113250732, epoch: 0 iter: 2\n",
      "loss: 2.0946359634399414, epoch: 0 iter: 3\n",
      "loss: 2.056750774383545, epoch: 0 iter: 4\n",
      "loss: 2.029942035675049, epoch: 0 iter: 5\n",
      "loss: 1.9939228296279907, epoch: 0 iter: 6\n",
      "loss: 1.9740431308746338, epoch: 0 iter: 7\n",
      "loss: 1.9895633459091187, epoch: 0 iter: 8\n",
      "loss: 1.9706158638000488, epoch: 0 iter: 9\n",
      "loss: 1.9679375886917114, epoch: 0 iter: 10\n",
      "loss: 1.944096326828003, epoch: 0 iter: 11\n",
      "loss: 1.8979072570800781, epoch: 0 iter: 12\n",
      "loss: 1.8981534242630005, epoch: 0 iter: 13\n",
      "loss: 2.005270481109619, epoch: 0 iter: 14\n",
      "loss: 1.9253475666046143, epoch: 0 iter: 15\n",
      "loss: 1.9024995565414429, epoch: 0 iter: 16\n",
      "loss: 1.832659125328064, epoch: 0 iter: 17\n",
      "loss: 1.8966102600097656, epoch: 0 iter: 18\n",
      "loss: 1.8803493976593018, epoch: 0 iter: 19\n",
      "loss: 1.9527474641799927, epoch: 0 iter: 20\n",
      "loss: 1.8729580640792847, epoch: 0 iter: 21\n",
      "loss: 1.9012987613677979, epoch: 0 iter: 22\n",
      "loss: 1.802640438079834, epoch: 0 iter: 23\n",
      "loss: 1.8630895614624023, epoch: 0 iter: 24\n",
      "loss: 1.86139976978302, epoch: 0 iter: 25\n",
      "loss: 1.8385366201400757, epoch: 0 iter: 26\n",
      "loss: 1.8732619285583496, epoch: 0 iter: 27\n"
     ]
    }
   ],
   "source": [
    "loss,e_loss = _lstm.train(train_data, train_labels, epoch=2, batch_size = 1000, update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([x for x in range(len(loss))], loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "with torch.no_grad():\n",
    "    pred = np.array([np.argmax(_lstm.predict(sample).view(75,2).mean(0)).data for sample in test_en])\n",
    "    print(np.average(pred == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "with torch.no_grad():\n",
    "    pred = np.array([np.argmax(_lstm.predict(sample).view(75,2).mean(0)).data for sample in test_es])\n",
    "    print(np.average(pred == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.4987, -4.7444],\n",
      "        [-3.1931, -3.8124],\n",
      "        [-3.6228, -3.6808],\n",
      "        [-4.4007, -4.3718],\n",
      "        [-3.3266, -3.3327]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    print(_lstm.predict(test_en[:5])[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.reshape(torch.tensor(test_en[0][0]), (3,13))\n",
    "print(f'{t[0]} \\n')\n",
    "print(f'{t[1]} \\n')\n",
    "print(f'{t[2]} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.2047,  0.0000,  0.0000,  0.0000,  2.3345,  1.3560,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000]) \n",
      "\n",
      "tensor([0.0136, 0.7787, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4182, 1.0459, 0.0000]) \n",
      "\n",
      "tensor([0.0734, 0.0000, 0.3271, 0.2432, 0.0000, 0.4300, 0.0229, 0.5136, 0.2651,\n",
      "        0.0000, 0.0000, 0.8104, 0.1049]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'{r(t[0])} \\n')\n",
    "print(f'{r(t[1])} \\n')\n",
    "print(f'{r(t[2])} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
