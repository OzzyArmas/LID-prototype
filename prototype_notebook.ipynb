{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'extractor.extractor' from '/Users/oosv/prototype/extractor/extractor.py'>"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "imp.reload(extractor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oosv/miniconda3/lib/python3.7/site-packages/mkl_fft/_numpy_fft.py:331: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  output = mkl_fft.rfft_numpy(a, n=n, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "from extractor import extractor\n",
    "import numpy as np\n",
    "import os\n",
    "path_en = 'data/voxforge/english'\n",
    "file_list = os.listdir(path_en)\n",
    "\n",
    "for f in range(len(file_list)):\n",
    "    file_list[f] = path_en + '/' + file_list[f]\n",
    "'''\n",
    "extracts 0.75s frames of features\n",
    "these are in a 3,75,13 ndarray\n",
    "3 - mfcc, delta, deltadelta\n",
    "75 - 75 25ms frames with a step of 10ms\n",
    "13 - cepstral features\n",
    "'''\n",
    "features_en = extractor.make_feature_set(file_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 75, 13)\n",
      "total samples:\t65917\n",
      "total hours:\t823.9625\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(features_en[2]))\n",
    "print(f\"total samples:\\t{len(features_en)}\")\n",
    "print(f\"total hours english:\\t{len(features_en) * 0.75 / 60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oosv/miniconda3/lib/python3.7/site-packages/mkl_fft/_numpy_fft.py:331: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  output = mkl_fft.rfft_numpy(a, n=n, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "path_es = 'data/voxforge/spanish'\n",
    "file_list = os.listdir(path_es)\n",
    "\n",
    "for f in range(len(file_list)):\n",
    "    file_list[f] = path_es + '/' + file_list[f]\n",
    "\n",
    "features_es = extractor.make_feature_set(file_list) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 75, 13)\n",
      "total samples:\t23472\n",
      "total hours spanish:\t293.4\n",
      "total hours combined:\t1117.3625\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(features_es[2]))\n",
    "print(f\"total samples:\\t{len(features_es)}\")\n",
    "print(f\"total hours spanish:\\t{len(features_es) * 0.75 / 60}\")\n",
    "print(f\"total hours combined:\\t{(len(features_es) + len(features_en)) * 0.75/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm_en = GaussianMixture(n_components=30, covariance_type='full', max_iter=100, random_state=0)\n",
    "train_en = features_en[:int(len(features_en) * 3 / 4)]\n",
    "sample_vectors = []\n",
    "for vec in train_en:\n",
    "    vec = np.swapaxes(vec,0,1)\n",
    "    if not len(vec) < 75:\n",
    "        vec = vec.reshape(75, 39)\n",
    "        sample_vectors.append(vec)\n",
    "shape = np.shape(sample_vectors)\n",
    "sample_vectors = np.array(sample_vectors).reshape((shape[0] * shape[1]), shape[2])\n",
    "gmm_en = gmm_en.fit(sample_vectors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65916\n",
      "23472\n"
     ]
    }
   ],
   "source": [
    "print(len(features_en))\n",
    "print(len(features_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_es = GaussianMixture(n_components=30, covariance_type='full', max_iter=100, random_state=0)\n",
    "train_es = features_es[:int(len(features_es) * 3 / 4)]\n",
    "sample_vectors = []\n",
    "for vec in train_es:\n",
    "    vec = np.swapaxes(vec,0,1)\n",
    "    if not len(vec) < 75:\n",
    "        vec = vec.reshape(75, 39)\n",
    "        gmm_es = gmm_es.fit(vec)\n",
    "        sample_vectors.append(vec)\n",
    "\n",
    "shape = np.shape(sample_vectors)\n",
    "sample_vectors = np.array(sample_vectors).reshape((shape[0] * shape[1]), shape[2])\n",
    "gmm_es = gmm_es.fit(sample_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-90.53250421112527\n",
      "-88.25573545834413\n"
     ]
    }
   ],
   "source": [
    "test_en = features_en[int(len(features_en) * 3 / 4) + 1:]\n",
    "test_es = features_es[int(len(features_es) * 3 / 4) + 1:]\n",
    "vec = test_es[12]\n",
    "#print(vec)\n",
    "#print(len(vec))\n",
    "vec = np.swapaxes(vec,0,1)\n",
    "if not len(vec) < 75:\n",
    "    vec = vec.reshape(75, 39)\n",
    "    pred_es = gmm_es.score(vec)\n",
    "    pred_en = gmm_en.score(vec)\n",
    "\n",
    "#show how the same vector gets different cluster sets\n",
    "print(pred_en)\n",
    "print(pred_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def make_cluster_dist(train_vectors, gmm):\n",
    "    '''\n",
    "    :param train_vectors: training vectors for each sample\n",
    "    :gmm: gmm model used for training\n",
    "    '''\n",
    "    cluster_dist = defaultdict(float)\n",
    "    for vec in train_vectors: #n_samples\n",
    "        vec = np.swapaxes(vec,0,1)\n",
    "        if not len(vec) < 75: #I should really change the 75 to a variable\n",
    "            vec = vec.reshape(75, 39)\n",
    "            for cluster in gmm.predict(vec): # 75 repetitions \n",
    "                cluster_dist[cluster] += 1\n",
    "    return cluster_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dist_en = make_cluster_dist(train_en, gmm_en)\n",
    "clusters_dist_es = make_cluster_dist(train_es, gmm_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>,\n",
      "            {0: 0.014600345647007993,\n",
      "             1: 0.022904785050766905,\n",
      "             2: 0.0293049254698639,\n",
      "             3: 0.019050820911643982,\n",
      "             4: 0.07232798660617844,\n",
      "             5: 0.028184813134586303,\n",
      "             6: 0.027146791963707066,\n",
      "             7: 0.036269712680924604,\n",
      "             8: 0.012612605314322747,\n",
      "             9: 0.023206416072585872,\n",
      "             10: 0.03339058111903219,\n",
      "             11: 0.02948098941456038,\n",
      "             12: 0.040017822423849644,\n",
      "             13: 0.02965138258803197,\n",
      "             14: 0.038668448909051634,\n",
      "             15: 0.018343864765608123,\n",
      "             16: 0.09080362929358393,\n",
      "             17: 0.03431410671851372,\n",
      "             18: 0.061123082739252536,\n",
      "             19: 0.035164182328796714,\n",
      "             20: 0.04244788291207604,\n",
      "             21: 0.036950205227910995,\n",
      "             22: 0.027558327932598832,\n",
      "             23: 0.024569291423633614,\n",
      "             24: 0.035100723698422986,\n",
      "             25: 0.03204444804493411,\n",
      "             26: 0.019075934327068483,\n",
      "             27: 0.024122380643767552,\n",
      "             28: 0.018652786779001944,\n",
      "             29: 0.04291072585871679})\n",
      "defaultdict(<class 'float'>,\n",
      "            {0: 0.02517761114898129,\n",
      "             1: 0.0589025221540559,\n",
      "             2: 0.02583428008785882,\n",
      "             3: 0.02917291524653488,\n",
      "             4: 0.008547299856093312,\n",
      "             5: 0.025658562447928503,\n",
      "             6: 0.02473225782019238,\n",
      "             7: 0.01587745209422101,\n",
      "             8: 0.0020374157388472315,\n",
      "             9: 0.04006286450049231,\n",
      "             10: 0.016862834204347497,\n",
      "             11: 0.026927970915700976,\n",
      "             12: 0.0223017496023631,\n",
      "             13: 0.031797318791183825,\n",
      "             14: 0.05914792092706203,\n",
      "             15: 0.05241838975990305,\n",
      "             16: 0.019654623949102477,\n",
      "             17: 0.016079678860864956,\n",
      "             18: 0.028153449973490872,\n",
      "             19: 0.03638642732712263,\n",
      "             20: 0.018851018707869423,\n",
      "             21: 0.037740665000378704,\n",
      "             22: 0.0376202378247368,\n",
      "             23: 0.08472922820571083,\n",
      "             24: 0.01889873513595395,\n",
      "             25: 0.05412027569491782,\n",
      "             26: 0.025237446034992048,\n",
      "             27: 0.023406801484511096,\n",
      "             28: 0.034844353556009997,\n",
      "             29: 0.09881769294857229})\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "total_clusters_en = sum(clusters_dist_en.values())\n",
    "total_clusters_es = sum(clusters_dist_es.values())\n",
    "clusters_prob_en = defaultdict(float)\n",
    "clusters_prob_es = defaultdict(float)\n",
    "for k in clusters_dist_en:\n",
    "    clusters_prob_en[k] = clusters_dist_en[k] / total_clusters_en\n",
    "    clusters_prob_es[k] = clusters_dist_es[k] / total_clusters_es\n",
    "pp.pprint(clusters_prob_en)\n",
    "pp.pprint(clusters_prob_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.87610976e-012, 1.83350841e-091, 1.93252533e-025, 8.99225301e-150,\n",
       "       2.15952519e-139, 7.06177624e-032, 4.88410910e-027, 1.89740301e-015,\n",
       "       1.63580634e-059, 1.95095285e-007, 9.99958410e-001, 1.64622486e-012,\n",
       "       4.09023695e-008, 3.31718549e-005, 4.94950900e-022, 3.33445260e-031,\n",
       "       2.22572532e-084, 6.57206939e-011, 8.62279721e-046, 2.80488183e-016,\n",
       "       2.79609452e-078, 3.91794360e-007, 4.32744147e-026, 7.78999306e-006,\n",
       "       6.08016839e-042, 4.00272194e-016, 0.00000000e+000, 5.38833250e-036,\n",
       "       2.16182534e-012, 2.75172867e-022])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_en.predict_proba(vec)[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bays_predict(test_vec, models, dists):\n",
    "    preds = []\n",
    "    scores = []\n",
    "    for gmm in models:\n",
    "        #cluster predictions per sample per model\n",
    "        preds.append(gmm.predict(test_vec))\n",
    "        scores.append(gmm.score_samples(test_vec))\n",
    "    #print(np.sum(scores[0]))\n",
    "    prob_sum = []\n",
    "    # sum(log(P(vec|z,lang)))\n",
    "    for pred,score,dist in zip(preds, scores, dists):\n",
    "        #print([dist[cluster] for cluster in pred])\n",
    "        prob_sum.append(np.sum(score) + np.sum(np.log([dist[cluster] for cluster in pred if dist[cluster] > 0])))\n",
    "    return prob_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english_preds = []\n",
    "# english_preds.append(bays_predict(vec, [gmm_en, gmm_es], [clusters_prob_en, clusters_prob_es]))\n",
    "# print(english_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7914668932451295\n"
     ]
    }
   ],
   "source": [
    "english_preds = []\n",
    "for vec in test_en:\n",
    "    vec = np.swapaxes(vec,0,1)\n",
    "    if not len(vec) < 75:\n",
    "        vec = vec.reshape(75, 39)\n",
    "        english_preds.append(np.argmax(bays_predict(vec, [gmm_en, gmm_es], [clusters_prob_en, clusters_prob_es])))\n",
    "\n",
    "print(np.average(np.array(english_preds) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6101926026930288\n"
     ]
    }
   ],
   "source": [
    "spanish_preds = []\n",
    "for vec in test_es:\n",
    "    vec = np.swapaxes(vec,0,1)\n",
    "    if not len(vec) < 75:\n",
    "        vec = vec.reshape(75, 39)\n",
    "        spanish_preds.append(np.argmax(bays_predict(vec, [gmm_en, gmm_es], [clusters_prob_en, clusters_prob_es])))\n",
    "\n",
    "print(np.average(np.array(spanish_preds) == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Saving a model\n",
    "with open('gmm_es','wb') as es_file:\n",
    "    pickle.dump(gmm_es, es_file)\n",
    "with open('gmm_en','wb') as en_file:\n",
    "    pickle.dump(gmm_en, en_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved model\n",
    "gmm_es_ld = []\n",
    "gmm_en_ld = []\n",
    "with open('gmm_es','rb') as es_file:\n",
    "    gmm_es_ld = pickle.load(es_file)\n",
    "    \n",
    "with open('gmm_en','rb') as en_file: \n",
    "    gmm_en_ld = pickle.load(en_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  4  4  4  4  4  4  4  4  4  4  4  4  4 16 16  2  2  2 16 16 16 16 16\n",
      " 16 16 16 16  4  4  4 16  4  4  4  4  4  4  4  4 16  4  4  4 16  4 16  4\n",
      "  4  4  4  4  4  4  4  4  4  4  4  4  4  2  2  2  2  4  4  4  4  4  4 16\n",
      "  4  4  4]\n",
      "(75, 39)\n"
     ]
    }
   ],
   "source": [
    "#validating models loaded are the same as saved models\n",
    "print(gmm_en_ld.predict(vec))\n",
    "print(np.shape(vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
