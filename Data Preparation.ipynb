{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Data Preparation\n",
    "\n",
    "This notebook shows how to extract data from wave files using extractor, and how the data is divided between test and training sets\n",
    "\n",
    "## Chunk Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractor import extractor\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import pprint as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extractor)\n",
    "wav_data = \"/home/ec2-user/SageMaker/voxforge/wav\" #Path to .wav file data\n",
    "languages = {\"english\" : 0, \"spanish\" : 1, \"french\" : 2, \"italian\" : 3, \"german\" : 4}\n",
    "TOTAL_FRAMES = 150\n",
    "MIN_ENERGY = 12\n",
    "npy_data    = \"/home/ec2-user/SageMaker/npy\"\n",
    "\n",
    "\n",
    "extractor.TOTAL_FRAMES = TOTAL_FRAMES # lenght of audio each clip will be divided into\n",
    "extractor.MIN_ENERGY = MIN_ENERGY # Minimum threshold of energy, zero's out anything not within threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lambda data : data[:len(data) // 4]\n",
    "train = lambda data : data[len(data) // 4 :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Block Below Will Taka a While"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped file /home/ec2-user/SageMaker/voxforge/wav/english/anonymous-20080731-jyq-a0573.wav\n",
      "skipped file /home/ec2-user/SageMaker/voxforge/wav/spanish/sg_ac_enrique-20141114-kij-es-0014.wav\n"
     ]
    }
   ],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in train(os.listdir(path)):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language])\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.concatenate(data_x, axis = 0)\n",
    "data_y = np.concatenate(data_y, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320890, 3, 150, 13) (320890,)\n"
     ]
    }
   ],
   "source": [
    "shape_x, shape_y = np.shape(data_x), np.shape(data_y)\n",
    "print(shape_x, shape_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320890, 3, 150, 13)\n",
      "total length of audio = 133.70416666666668 hours\n"
     ]
    }
   ],
   "source": [
    "# Convert from Sup_Seq x 3 x TOTAL_FRAMES x n_coeff\n",
    "#         to   Sup_Seq x TOTAL_FRAMES x n_coeff * 3\n",
    "shape_x = np.shape(data_x)\n",
    "print(shape_x)\n",
    "print(f'total length of audio = {shape_x[0] * (TOTAL_FRAMES/100) / 3600} hours' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution(data_y):\n",
    "    counts = Counter(data_y)\n",
    "    total = sum(counts.values())\n",
    "    weights = {k : counts[k] / total for k in counts}\n",
    "    #print(weights)\n",
    "    return(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 141305, 1: 68145, 2: 48961, 4: 38634, 3: 23845})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.4403533921281436,\n",
       " 1: 0.21236249181962666,\n",
       " 2: 0.1525787653089844,\n",
       " 3: 0.07430895322384617,\n",
       " 4: 0.12039639751939916}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy and paste the weights below onto the train script\n",
    "label_distribution(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_in_unison(data_x, data_y)\n",
    "shape_x = np.shape(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(npy_data, 'train_x.npy'), 'wb') as file:\n",
    "    np.save(file, data_x)\n",
    "with open(os.path.join(npy_data,'train_y.npy'), 'wb') as file:\n",
    "    np.save(file, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Block Below Will Taka a While"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in test(os.listdir(path)):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language])\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)\n",
    "data_x = np.concatenate(data_x, axis = 0)\n",
    "data_y = np.concatenate(data_y, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106555, 3, 150, 13) (106555,)\n",
      "total length of audio = 44.39791666666667 hours\n",
      "Counter({0: 46928, 1: 22733, 2: 16349, 4: 12664, 3: 7881})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.44041105532354186,\n",
       " 1: 0.21334522077800197,\n",
       " 2: 0.15343249964806907,\n",
       " 3: 0.07396180376331472,\n",
       " 4: 0.11884942048707241}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_x, shape_y = np.shape(data_x), np.shape(data_y)\n",
    "print(shape_x, shape_y)\n",
    "print(f'total length of audio = {shape_x[0] * (TOTAL_FRAMES/100) / 3600} hours' )\n",
    "label_distribution(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_in_unison(data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(npy_data,'test_x.npy'), 'wb') as file:\n",
    "    np.save(file, data_x)\n",
    "with open(os.path.join(npy_data,'test_y.npy'), 'wb') as file:\n",
    "    np.save(file, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Utterance Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractor import extractor\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import pprint as p\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Specific\n",
    "importlib.reload(extractor)\n",
    "wav_data   = \"/home/ec2-user/SageMaker/voxforge/wav\" #Path to .wav file data\n",
    "npy_data    = \"/home/ec2-user/SageMaker/npy\"\n",
    "languages  = {\"english\" : 0, \"spanish\" : 1, \"french\" : 2, \"italian\" : 3, \"german\" : 4}\n",
    "MIN_ENERGY = 12\n",
    "\n",
    "extractor.MIN_ENERGY = MIN_ENERGY \n",
    "max_padding = 800\n",
    "\n",
    "# Sage Maker Specific\n",
    "role         = get_execution_role()\n",
    "sess         = sage.Session()\n",
    "bucket       = 'oosv-multilingual-bucket' # feel free to change the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_samples(X, max_padding): \n",
    "    out = []\n",
    "    for idx, x in enumerate(X):\n",
    "        if len(x[0]) > max_padding:\n",
    "            shorted = np.array([x[0][:int(max_padding)],\n",
    "                       x[1][:int(max_padding)],\n",
    "                       x[2][:int(max_padding)]])\n",
    "            out.append(shorted)\n",
    "\n",
    "        else:\n",
    "            shape = np.shape(x)\n",
    "            zeros = np.zeros([shape[0], int(max_padding) - shape[1], shape[2]])\n",
    "            out.append(np.concatenate((zeros, x), axis = 1))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Block Below Will Taka a While"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped file /home/ec2-user/SageMaker/voxforge/wav/english/anonymous-20080731-jyq-a0573.wav\n",
      "skipped file /home/ec2-user/SageMaker/voxforge/wav/spanish/sg_ac_enrique-20141114-kij-es-0014.wav\n"
     ]
    }
   ],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in train(os.listdir(path)):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language], chunk=False)\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118870 118870\n",
      "(118870, 3, 800, 13)\n",
      "Counter({0: 61166, 4: 17618, 2: 16761, 1: 16485, 3: 6840})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.13868091192058551,\n",
       " 4: 0.14821233280053842,\n",
       " 0: 0.514562126693026,\n",
       " 2: 0.14100277614200388,\n",
       " 3: 0.05754185244384622}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_x), len(data_y))\n",
    "print(np.shape(data_x))\n",
    "#data_y = np.concatenate(data_y)\n",
    "label_distribution(data_y)\n",
    "# all utterance lengths are different but a single sample of X shaped\n",
    "# deltas (3) x length_utterance x ceptra\n",
    "# the first index is tha language index, second is utterance index\n",
    "# languages can't be concatenated to be shuffled until all utterances are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6aefaf423014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_x_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata_x_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_padding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_x_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-c96bcafa2aef>\u001b[0m in \u001b[0;36madjust_samples\u001b[0;34m(X, max_padding)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mzeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_padding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "data_x_ = []\n",
    "data_x_ = adjust_samples(lang, max_padding)\n",
    "\n",
    "data_x_ = np.concatenate(data_x_)\n",
    "print(np.shape(data_x_))\n",
    "print(np.shape(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 4 ... 3 4 4]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the value above looks right, replace data_x\n",
    "data_x = data_x_\n",
    "shuffle_in_unison(data_x, data_y)\n",
    "with open(os.path.join(npy_data ,'full_train_x.npy'), 'wb') as npy:\n",
    "    np.save(npy, data_x)\n",
    "    \n",
    "with open(os.path.join(npy_data ,'full_train_y.npy'), 'wb') as npy:\n",
    "    np.save(npy, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Block Below Will Taka a While"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in test(os.listdir(path)):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language], chunk=False)\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n",
      "(3, 455, 13)\n",
      "Counter({0: 20387, 4: 5872, 2: 5585, 1: 5497, 3: 2278})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.5145763396350236,\n",
       " 1: 0.13874656099346272,\n",
       " 2: 0.14096771750927586,\n",
       " 3: 0.0574976652616169,\n",
       " 4: 0.1482117166006209}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_x), len(data_y))\n",
    "data_y = np.concatenate(data_y)\n",
    "print(np.shape(data_x[0][0])) \n",
    "label_distribution(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39619, 3, 800, 13)\n",
      "(39619,)\n"
     ]
    }
   ],
   "source": [
    "data_x_ = []\n",
    "for lang in data_x:\n",
    "    data_x_.append(adjust_samples(lang, max_padding))\n",
    "\n",
    "data_x_ = np.concatenate(data_x_)\n",
    "print(np.shape(data_x_))\n",
    "print(np.shape(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = data_x_\n",
    "shuffle_in_unison(data_x, data_y)\n",
    "with open(os.path.join(npy_data ,'full_test_x.npy'), 'wb') as npy:\n",
    "    np.save(npy, data_x)\n",
    "    \n",
    "with open(os.path.join(npy_data ,'full_test_y.npy'), 'wb') as npy:\n",
    "    np.save(npy, data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Train and Test Files to Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['train', 'test']\n",
    "files = ['full_{0}_y.npy', 'full_{0}_x.npy', '{0}_x.npy', '{0}_y.npy']\n",
    "def upload_data(file_name, file_path, channel):\n",
    "    target = f'data/{channel}/{channel}_5/'\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket).upload_file(file_path, target + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Block Below Will Taka a While"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = '/full_{0}_x.npy'\n",
    "for channel in ['train', 'test']:\n",
    "    for file in files:\n",
    "        upload_data(file.format(channel), os.path.join(npy_data, file.format(channel)), channel)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
