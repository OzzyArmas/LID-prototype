{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Data Preparation\n",
    "\n",
    "This notebook shows how to extract data from wave files using extractor, and how the data is divided between test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import gmm, lstm\n",
    "from extractor import extractor\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extractor)\n",
    "wav_data = \"/Users/oosv/data/voxforge\" #Path to .wav file data\n",
    "languages = {\"english\" : 0, \"spanish\" : 1, \"french\" : 2}\n",
    "TOTAL_FRAMES = 150\n",
    "ENERGY_MIN = 12\n",
    "DELTA_DIM = 3\n",
    "CEPSTRAL_COEF = 13\n",
    "\n",
    "extractor.TOTAL_FRAMES = TOTAL_FRAMES # lenght of audio each clip will be divided into\n",
    "extractor.MIN_ENERGY = ENERGY_MIN # Minimum threshold of energy, zero's out anything not within threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oosv/miniconda3/lib/python3.6/site-packages/mkl_fft/_numpy_fft.py:331: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  output = mkl_fft.rfft_numpy(a, n=n, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in os.listdir(path):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language])\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(data_y))\n",
    "print(len(data_x))\n",
    "data_x = np.concatenate(data_x, axis = 0)\n",
    "data_y = np.concatenate(data_y, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314809, 3, 150, 13) (314809,)\n"
     ]
    }
   ],
   "source": [
    "shape_x, shape_y = np.shape(data_x), np.shape(data_y)\n",
    "print(shape_x, shape_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314809, 150, 39)\n",
      "total length of audio = 13.117041666666665 hours\n"
     ]
    }
   ],
   "source": [
    "# Convert from Sup_Seq x 3 x TOTAL_FRAMES x n_coeff\n",
    "#         to   Sup_Seq x TOTAL_FRAMES x n_coeff * 3\n",
    "data_x = np.reshape(data_x, [shape_x[0], shape_x[2], shape_x[1] * shape_x[3]])\n",
    "shape_x = np.shape(data_x)\n",
    "print(shape_x)\n",
    "print(f'total length of audio = {shape_x[0] * .150 / 3600} hours' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 154673, 1: 96687, 2: 63449})\n"
     ]
    }
   ],
   "source": [
    "# number of samples per language\n",
    "counts = Counter(data_y)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_equal(counts, data_x, data_y):\n",
    "    low_idx = min(counts, key=counts.get)\n",
    "    low = counts[low_idx]\n",
    "    new_y, new_x = [],[]\n",
    "    begin = 0\n",
    "    for idx in range(len(counts)):\n",
    "        new_y += data_y[begin: begin + low].tolist()\n",
    "        new_x += data_x[begin: begin + low].tolist()\n",
    "        begin += counts[idx]\n",
    "    return new_x, new_y\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = make_equal(counts, data_x, data_y)\n",
    "print(np.shape(data_x), np.shape(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_in_unison(data_x, data_y)\n",
    "shape_x = np.shape(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190347, 150, 39)\n",
      "total length of audio = 7.931125 hours\n"
     ]
    }
   ],
   "source": [
    "print(shape_x)\n",
    "print(f'total length of audio = {shape_x[0] * .150 / 3600} hours' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_x[int(shape_x[0]/4):]\n",
    "test_x = data_x[:int(shape_x[0]/4)]\n",
    "train_y = data_y[int(shape_x[0]/4):]\n",
    "test_y = data_y[:int(shape_x[0]/4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142761, 150, 39) (142761,)\n",
      "(47586, 150, 39) (47586,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_x), np.shape(train_y))\n",
    "print(np.shape(test_x), np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_x_3.npy', 'wb') as file:\n",
    "    np.save(file, train_x)\n",
    "with open('train_y_3.npy', 'wb') as file:\n",
    "    np.save(file, train_y)\n",
    "with open('test_x_3.npy', 'wb') as file:\n",
    "    np.save(file, test_x)\n",
    "with open('test_y_3.npy', 'wb') as file:\n",
    "    np.save(file, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
