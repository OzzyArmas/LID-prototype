{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Data Preparation\n",
    "\n",
    "This notebook shows how to extract data from wave files using extractor, and how the data is divided between test and training sets\n",
    "\n",
    "## Chunk Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import gmm, lstm\n",
    "from extractor import extractor\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import pprint as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extractor)\n",
    "wav_data = \"/tmp/data/voxforge\" #Path to .wav file data\n",
    "languages = {\"english\" : 0, \"spanish\" : 1, \"french\" : 2, \"italian\" : 3, \"german\" : 4}\n",
    "TOTAL_FRAMES = 150\n",
    "MIN_ENERGY = 12\n",
    "\n",
    "extractor.TOTAL_FRAMES = TOTAL_FRAMES # lenght of audio each clip will be divided into\n",
    "extractor.MIN_ENERGY = MIN_ENERGY # Minimum threshold of energy, zero's out anything not within threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oosv/miniconda3/lib/python3.6/site-packages/mkl_fft/_numpy_fft.py:331: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  output = mkl_fft.rfft_numpy(a, n=n, axis=axis)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b87b09b53b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_feature_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdata_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdata_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prototype/extractor/extractor.py\u001b[0m in \u001b[0;36mmake_feature_set\u001b[0;34m(file_list, language_label, chunk)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# at this point out_feats is either []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# or it's n_subsequences x 3 x TOTAL_FRAMES x 13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfeature_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prototype/extractor/extractor.py\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(input_file, chunk)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# and the remaining 13 are mfcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prototype/extractor/extractor.py\u001b[0m in \u001b[0;36mfilter_energy\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# clean up reverse file, then return it to oringal order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclean_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/prototype/extractor/extractor.py\u001b[0m in \u001b[0;36mclean_up\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mstart_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_frame\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in os.listdir(path):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language])\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(data_y))\n",
    "print(len(data_x))\n",
    "data_x = np.concatenate(data_x, axis = 0)\n",
    "data_y = np.concatenate(data_y, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403374, 3, 150, 13) (403374,)\n"
     ]
    }
   ],
   "source": [
    "shape_x, shape_y = np.shape(data_x), np.shape(data_y)\n",
    "print(shape_x, shape_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403374, 150, 39)\n",
      "total length of audio = 168.0725 hours\n"
     ]
    }
   ],
   "source": [
    "# Convert from Sup_Seq x 3 x TOTAL_FRAMES x n_coeff\n",
    "#         to   Sup_Seq x TOTAL_FRAMES x n_coeff * 3\n",
    "data_x = np.reshape(data_x, [shape_x[0], shape_x[2], shape_x[1] * shape_x[3]])\n",
    "shape_x = np.shape(data_x)\n",
    "print(shape_x)\n",
    "print(f'total length of audio = {shape_x[0] * 1.50 / 3600} hours' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 154673, 1: 96687, 2: 63449, 4: 52284, 3: 36281})\n",
      "{0: 0.38344811514872057, 1: 0.23969566704844636, 2: 0.15729571068041073, 3: 0.08994382384586017, 4: 0.1296166832765622}\n"
     ]
    }
   ],
   "source": [
    "counts = Counter(data_y)\n",
    "print(counts)\n",
    "total = sum(counts.values())\n",
    "weights = {k : counts[k] / total for k in counts}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_equal(counts, data_x, data_y):\n",
    "#     low_idx = min(counts, key=counts.get)\n",
    "#     low = counts[low_idx]\n",
    "#     data_x = data_x.tolist()\n",
    "#     data_y = data_y.tolist()\n",
    "#     #print(low)\n",
    "#     new_y, new_x = [],[]\n",
    "#     begin = 0\n",
    "#     for idx in range(len(counts)):\n",
    "#         new_y += data_y[begin: begin + low]\n",
    "#         new_x += data_x[begin: begin + low]\n",
    "#         #print(begin)\n",
    "#         #print(begin + low)\n",
    "#         begin += counts[idx]\n",
    "#     return new_x, new_y\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(data_y_)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_in_unison(data_x, data_y)\n",
    "shape_x = np.shape(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_x[int(shape_x[0]/4):]\n",
    "test_x = data_x[:int(shape_x[0]/4)]\n",
    "train_y = data_y[int(shape_x[0]/4):]\n",
    "test_y = data_y[:int(shape_x[0]/4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302531, 150, 39) (302531,)\n",
      "(100843, 150, 39) (100843,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_x), np.shape(train_y))\n",
    "print(np.shape(test_x), np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_5_lang_audio =  168.0725 hours\n"
     ]
    }
   ],
   "source": [
    "print(f'total_5_lang_audio =  {shape_x[0] * 1.50 / 3600} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_x_5.npy', 'wb') as file:\n",
    "    np.save(file, train_x)\n",
    "with open('train_y_5.npy', 'wb') as file:\n",
    "    np.save(file, train_y)\n",
    "with open('test_x_5.npy', 'wb') as file:\n",
    "    np.save(file, test_x)\n",
    "with open('test_y_5.npy', 'wb') as file:\n",
    "    np.save(file, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Utterance Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import gmm, lstm\n",
    "from extractor import extractor\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "import pprint as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extractor)\n",
    "wav_data = \"/Users/oosv/data/voxforge\" #Path to .wav file data\n",
    "languages = {\"english\" : 0, \"spanish\" : 1, \"french\" : 2, \"italian\" : 3, \"german\" : 4}\n",
    "MIN_ENERGY = 12\n",
    "\n",
    "extractor.MIN_ENERGY = MIN_ENERGY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oosv/miniconda3/lib/python3.6/site-packages/mkl_fft/_numpy_fft.py:331: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  output = mkl_fft.rfft_numpy(a, n=n, axis=axis)\n"
     ]
    }
   ],
   "source": [
    "data_y = []\n",
    "data_x = []\n",
    "# num_samples = 100\n",
    "# get the path for num_samples .wav files\n",
    "for language in languages:\n",
    "    \n",
    "    files = []\n",
    "    path = os.path.join(wav_data, language)\n",
    "    for f in os.listdir(path):\n",
    "        files.append(os.path.join(path, f))\n",
    "    \n",
    "    x, y = extractor.make_feature_set(files, languages[language], chunk=False)\n",
    "    data_x.append(x)\n",
    "    data_y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5\n"
     ]
    }
   ],
   "source": [
    "print(len(data_x), len(data_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 pad all sequences to ensure equal dimensions for training purposes\n",
    "# no special need for padding in case of test data though\n",
    "def get_length_metrics(X):\n",
    "    longest = 0\n",
    "    sum_lengths = 0\n",
    "    for idx, x in enumerate(X):\n",
    "        cur = len(x[0])\n",
    "        sum_lengths += cur\n",
    "        if cur > longest:\n",
    "            longest = cur\n",
    "    avg = sum_lengths/(idx + 1)\n",
    "    sum_diff = 0\n",
    "    for idx, x in enumerate(X):\n",
    "        sum_diff += (len(x[0]) - avg)**2\n",
    "    std_dev = (sum_diff / idx) ** (1/2)\n",
    "    return longest, avg, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_samples(X, avg, std_dev): \n",
    "    out = []\n",
    "    for idx, x in enumerate(X):\n",
    "        if len(x[0]) > avg + std_dev:\n",
    "            shorted = np.array([x[0][:int(avg + std_dev)],\n",
    "                       x[1][:int(avg + std_dev)],\n",
    "                       x[2][:int(avg + std_dev)]])\n",
    "            out.append(shorted)\n",
    "\n",
    "        else:\n",
    "            shape = np.shape(x)\n",
    "            zeros = np.zeros([shape[0], int(avg + std_dev) - shape[1], shape[2]])\n",
    "            out.append(np.concatenate((zeros, x), axis = 1))\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_metrics(data_x):\n",
    "    longest = 0\n",
    "    metrics = {}\n",
    "    for idx, lang in enumerate(data_x):\n",
    "        metrics[idx] = get_length_metrics(lang)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mets = get_language_metrics(data_x)\n",
    "p.pprint (mets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lang_1 = adjust_samples(data_x[0],550, 250)\n",
    "lang = adjust_samples(data_x[4], 550, 250)\n",
    "    \n",
    "with open('temp_{}.npy'.format(4), 'wb') as npy:\n",
    "    np.save(npy, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68365, 3, 800, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_en = np.load('temp_0.npy')\n",
    "np.shape(data_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23227, 3, 800, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_es = np.load('temp_1.npy')\n",
    "np.shape(data_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21657, 3, 800, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fr = np.load('temp_2.npy')\n",
    "np.shape(data_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10294, 3, 800, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_it = np.load('temp_3.npy')\n",
    "np.shape(data_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23937, 3, 800, 13)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_de = np.load('temp_4.npy')\n",
    "np.shape(data_de)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation from Sagemaker Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import time\n",
    "\n",
    "role         = get_execution_role()\n",
    "sess         = sage.Session()\n",
    "bucket       = 'oosv-multilingual-bucket' \n",
    "path         = '/tmp/data/npy/'\n",
    "def get_data(file_name, bucket):\n",
    "    file = os.path.join('/tmp/data/voxforge', file_name)\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket).download_file('data/tmp/' + file_name, file)\n",
    "    data = np.load(file)\n",
    "    os.remove(file)\n",
    "    return data\n",
    "\n",
    "path = '/home/ec2-user/SageMaker/data/npy/'\n",
    "def upload_data(file_name, channel):\n",
    "    target = f'data/{channel}/{channel}_5/'\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.Bucket(bucket).upload_file(os.path.join(path, file_name), target + file_name)\n",
    "    \n",
    "file_info = {\"english\" : \"temp_0.npy\",\n",
    "             \"spanish\" : \"temp_1.npy\",\n",
    "             \"french\"  : \"temp_2.npy\",\n",
    "             \"italitan\": \"temp_3.npy\", \n",
    "             \"german\"  : \"temp_4.npy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y = [0] * 68365 + [1] * 23227 + [2] * 21657 + [3] * 10294 + [4] * 23937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = []\n",
    "for lang in file_info:\n",
    "    data_x.append(get_data(file_info[lang], bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147480, 3, 800, 13)\n"
     ]
    }
   ],
   "source": [
    "#data_x = np.concatenate(data_x, axis = 0)\n",
    "print(np.shape(data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_in_unison(data_x, data_y)\n",
    "shape_x = np.shape(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_x[int(shape_x[0]/4):]\n",
    "test_x = data_x[:int(shape_x[0]/4)]\n",
    "train_y = data_y[int(shape_x[0]/4):]\n",
    "test_y = data_y[:int(shape_x[0]/4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110610, 3, 800, 13) (110610,)\n",
      "(36870, 3, 800, 13) (36870,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_x), np.shape(train_y))\n",
    "print(np.shape(test_x), np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_5_lang_audio =  61.45 hours\n"
     ]
    }
   ],
   "source": [
    "print(f'total_5_lang_audio =  {shape_x[0] * .50 / 3600} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'full_train_x.npy'\n",
    "with open(os.path.join(path,file_name), 'wb') as file:\n",
    "    np.save(file, train_x)\n",
    "upload_data(file_name, 'train')\n",
    "os.remove(os.path.join(path,file_name))\n",
    "\n",
    "file_name = 'full_train_y.npy'\n",
    "with open(os.path.join(path,file_name), 'wb') as file:\n",
    "    np.save(file, train_y)\n",
    "upload_data(file_name, 'train')\n",
    "os.remove(os.path.join(path,file_name))\n",
    "\n",
    "file_name = 'full_test_x.npy'\n",
    "with open(os.path.join(path,file_name), 'wb') as file:\n",
    "    np.save(file, test_x)\n",
    "upload_data(file_name, 'test')\n",
    "os.remove(os.path.join(path,file_name))\n",
    "\n",
    "file_name = 'full_test_y.npy'\n",
    "with open(os.path.join(path,file_name), 'wb') as file:\n",
    "    np.save(file, test_y)\n",
    "upload_data(file_name, 'test')\n",
    "os.remove(os.path.join(path,file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
